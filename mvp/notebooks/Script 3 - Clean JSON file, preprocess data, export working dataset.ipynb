{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare working db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load json file with parsed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_to_json_file = os.path.abspath('../data/json/')\n",
    "\n",
    "### json file\n",
    "json_file = '/all_parsed_data_json' #name json file  \n",
    "# json_file = '/sample_json' #sample json file for testing  \n",
    "\n",
    "file = '{}{}.json'.format(path_to_json_file, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "df = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataframe\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311536, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column type\n",
    "def data_types(dataframe, cols = [], to_type = ''):\n",
    "    for col in cols:\n",
    "        dataframe[col] = df[col].astype(to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dates = ['study_first_submitted', 'last_update_submitted', 'verification_date']\n",
    "data_types(df, columns_dates, 'datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year \n",
    "df['year_submitted'] = df['study_first_submitted'].dt.year\n",
    "df['year_last_updated'] = df['last_update_submitted'].dt.year\n",
    "df['year_verification'] = df['verification_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecesary columns\n",
    "df.drop(columns_dates, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['study_first_posted', 'last_update_posted']\n",
    "df.drop(columns_to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove /n in all df\n",
    "df = df.replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for all text\n",
    "df['all_text'] = df['source'] + ' ' + df['brief_title'] + ' ' + df['condition'] + ' ' + df['condition_browse/mesh_term'] + ' '+ df['intervention_browse/mesh_term'] + ' '+ df['detailed_description/textblock'] + ' ' + df['brief_summary/textblock']\n",
    "\n",
    "# All_text in lowercase\n",
    "df['all_text'] = df['all_text'].str.lower()\n",
    "\n",
    "# remove extra whitespace\n",
    "df.all_text = df.all_text.replace('\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This study was conducted to compare the activities of erlotinib to that of intravenous, platinum-based therapy in the treatment of non-small cell lung cancer (NSCLC). The goal of this trial was to demonstrate clinical equivalence of erlotinib to platinum-based frontline therapy, compared to historical controls. '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove extra white space in summary\n",
    "df['brief_summary/textblock'] = df['brief_summary/textblock'].replace('\\s+', ' ', regex=True)\n",
    "df['brief_summary/textblock'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add url columns\n",
    "url_string = 'https://clinicaltrials.gov/ct2/show/'\n",
    "df['url'] = url_string + df['nct_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>source</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>study_type</th>\n",
       "      <th>phase</th>\n",
       "      <th>condition</th>\n",
       "      <th>condition_browse/mesh_term</th>\n",
       "      <th>intervention_browse/mesh_term</th>\n",
       "      <th>detailed_description/textblock</th>\n",
       "      <th>...</th>\n",
       "      <th>sponsors/lead_sponsor/agency</th>\n",
       "      <th>sponsors/lead_sponsor/agency_class</th>\n",
       "      <th>study_design_info/allocation</th>\n",
       "      <th>study_design_info/intervention_model</th>\n",
       "      <th>study_design_info/primary_purpose</th>\n",
       "      <th>year_submitted</th>\n",
       "      <th>year_last_updated</th>\n",
       "      <th>year_verification</th>\n",
       "      <th>all_text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00391586</td>\n",
       "      <td>New Mexico Cancer Care Alliance</td>\n",
       "      <td>Erlotinib and Standard Platinum-Based Chemothe...</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Phase 2</td>\n",
       "      <td>Carcinoma, Non-Small-Cell Lung</td>\n",
       "      <td>Carcinoma</td>\n",
       "      <td>Paclitaxel</td>\n",
       "      <td>To compare the activities (the progress...</td>\n",
       "      <td>...</td>\n",
       "      <td>New Mexico Cancer Care Alliance</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Single Group Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>2006</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>new mexico cancer care alliance erlotinib and ...</td>\n",
       "      <td>https://clinicaltrials.gov/ct2/show/NCT00391586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT03472664</td>\n",
       "      <td>Wake Forest University Health Sciences</td>\n",
       "      <td>Brain Energy for Amyloid Transformation in Alz...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Alzheimer Disease</td>\n",
       "      <td>Alzheimer Disease</td>\n",
       "      <td>None</td>\n",
       "      <td>This study will examine the effects of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>Wake Forest University Health Sciences</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>wake forest university health sciences brain e...</td>\n",
       "      <td>https://clinicaltrials.gov/ct2/show/NCT03472664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCT01009658</td>\n",
       "      <td>Gunma University</td>\n",
       "      <td>MSG and Gastrointestinal Motility</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Phase 3</td>\n",
       "      <td>Gastroesophageal Reflux</td>\n",
       "      <td>Gastroesophageal Reflux</td>\n",
       "      <td>None</td>\n",
       "      <td>Amino acids such as monosodium glutamat...</td>\n",
       "      <td>...</td>\n",
       "      <td>Gunma University</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Crossover Assignment</td>\n",
       "      <td>Basic Science</td>\n",
       "      <td>2009</td>\n",
       "      <td>2015</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>gunma university msg and gastrointestinal moti...</td>\n",
       "      <td>https://clinicaltrials.gov/ct2/show/NCT01009658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NCT03651011</td>\n",
       "      <td>Odense University Hospital</td>\n",
       "      <td>Navigated Laser In Branch Retinal Vein Occlusi...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Phase 1</td>\n",
       "      <td>Branch Retinal Vein Occlusion</td>\n",
       "      <td>Macular Edema</td>\n",
       "      <td>None</td>\n",
       "      <td>Purpose of the study        In a 12-mon...</td>\n",
       "      <td>...</td>\n",
       "      <td>Odense University Hospital</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>odense university hospital navigated laser in ...</td>\n",
       "      <td>https://clinicaltrials.gov/ct2/show/NCT03651011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NCT02424045</td>\n",
       "      <td>Samsung Medical Center</td>\n",
       "      <td>Bendamustine, Carboplatin and Dexamethasone (B...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Phase 1</td>\n",
       "      <td>T-cell Lymphoma</td>\n",
       "      <td>Lymphoma</td>\n",
       "      <td>Dexamethasone</td>\n",
       "      <td>Peripheral T-cell lymphoma (PTCL) repre...</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung Medical Center</td>\n",
       "      <td>Other</td>\n",
       "      <td>None</td>\n",
       "      <td>Single Group Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>2015</td>\n",
       "      <td>2018</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>samsung medical center bendamustine, carboplat...</td>\n",
       "      <td>https://clinicaltrials.gov/ct2/show/NCT02424045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           nct_id                                  source  \\\n",
       "0     NCT00391586         New Mexico Cancer Care Alliance   \n",
       "1     NCT03472664  Wake Forest University Health Sciences   \n",
       "10    NCT01009658                        Gunma University   \n",
       "100   NCT03651011              Odense University Hospital   \n",
       "1000  NCT02424045                  Samsung Medical Center   \n",
       "\n",
       "                                            brief_title overall_status  \\\n",
       "0     Erlotinib and Standard Platinum-Based Chemothe...     Terminated   \n",
       "1     Brain Energy for Amyloid Transformation in Alz...     Recruiting   \n",
       "10                    MSG and Gastrointestinal Motility      Completed   \n",
       "100   Navigated Laser In Branch Retinal Vein Occlusi...     Recruiting   \n",
       "1000  Bendamustine, Carboplatin and Dexamethasone (B...      Completed   \n",
       "\n",
       "          study_type    phase                       condition  \\\n",
       "0     Interventional  Phase 2  Carcinoma, Non-Small-Cell Lung   \n",
       "1     Interventional      N/A               Alzheimer Disease   \n",
       "10    Interventional  Phase 3         Gastroesophageal Reflux   \n",
       "100   Interventional  Phase 1   Branch Retinal Vein Occlusion   \n",
       "1000  Interventional  Phase 1                 T-cell Lymphoma   \n",
       "\n",
       "     condition_browse/mesh_term intervention_browse/mesh_term  \\\n",
       "0                     Carcinoma                    Paclitaxel   \n",
       "1             Alzheimer Disease                          None   \n",
       "10      Gastroesophageal Reflux                          None   \n",
       "100               Macular Edema                          None   \n",
       "1000                   Lymphoma                 Dexamethasone   \n",
       "\n",
       "                         detailed_description/textblock  ...  \\\n",
       "0            To compare the activities (the progress...  ...   \n",
       "1            This study will examine the effects of ...  ...   \n",
       "10           Amino acids such as monosodium glutamat...  ...   \n",
       "100          Purpose of the study        In a 12-mon...  ...   \n",
       "1000         Peripheral T-cell lymphoma (PTCL) repre...  ...   \n",
       "\n",
       "                sponsors/lead_sponsor/agency  \\\n",
       "0            New Mexico Cancer Care Alliance   \n",
       "1     Wake Forest University Health Sciences   \n",
       "10                          Gunma University   \n",
       "100               Odense University Hospital   \n",
       "1000                  Samsung Medical Center   \n",
       "\n",
       "     sponsors/lead_sponsor/agency_class study_design_info/allocation  \\\n",
       "0                                 Other                         None   \n",
       "1                                 Other                   Randomized   \n",
       "10                                Other                   Randomized   \n",
       "100                               Other                   Randomized   \n",
       "1000                              Other                         None   \n",
       "\n",
       "     study_design_info/intervention_model study_design_info/primary_purpose  \\\n",
       "0                 Single Group Assignment                         Treatment   \n",
       "1                     Parallel Assignment                         Treatment   \n",
       "10                   Crossover Assignment                     Basic Science   \n",
       "100                   Parallel Assignment                         Treatment   \n",
       "1000              Single Group Assignment                         Treatment   \n",
       "\n",
       "     year_submitted year_last_updated year_verification  \\\n",
       "0              2006              2015            2015.0   \n",
       "1              2018              2018            2018.0   \n",
       "10             2009              2015            2015.0   \n",
       "100            2018              2019            2019.0   \n",
       "1000           2015              2018            2007.0   \n",
       "\n",
       "                                               all_text  \\\n",
       "0     new mexico cancer care alliance erlotinib and ...   \n",
       "1     wake forest university health sciences brain e...   \n",
       "10    gunma university msg and gastrointestinal moti...   \n",
       "100   odense university hospital navigated laser in ...   \n",
       "1000  samsung medical center bendamustine, carboplat...   \n",
       "\n",
       "                                                  url  \n",
       "0     https://clinicaltrials.gov/ct2/show/NCT00391586  \n",
       "1     https://clinicaltrials.gov/ct2/show/NCT03472664  \n",
       "10    https://clinicaltrials.gov/ct2/show/NCT01009658  \n",
       "100   https://clinicaltrials.gov/ct2/show/NCT03651011  \n",
       "1000  https://clinicaltrials.gov/ct2/show/NCT02424045  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "- Tokenize, Lemmatize / Stem\n",
    "- Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "# porter_stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# def stem_sentences(text):\n",
    "#     tokens = text.split()\n",
    "#     stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "#     return ' '.join(stemmed_tokens)\n",
    "\n",
    "# df['stems'] = df['all_text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "def lemm_sentences(text):\n",
    "    tokens = text.split()\n",
    "    lemm_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemm_tokens)\n",
    "\n",
    "df['lemmas'] = df['all_text'].apply(lemm_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words [not needed with countvectorizer]\n",
    "# stop_words = stopwords.words('english')\n",
    "# df['tokens'] = df['lemmas'].apply(lambda x: [item for item in x.split() if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lemmas[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_numbers = lambda x: re.sub(r'(\\d)+', '', x.lower())\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                     preprocessor = pat_numbers,\n",
    "                     max_features = 1800,\n",
    "                     lowercase = True,\n",
    "                     max_df = 0.8,\n",
    "                     ngram_range = (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df['lemmas'])\n",
    "\n",
    "X = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(X.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nct_id to word_counts df\n",
    "nct_id = df['nct_id']\n",
    "\n",
    "df_word_counts = pd.merge(nct_id, word_counts, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all dataframes in space\n",
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export datasets: df, df_word_counts (key: ntc_id)\n",
    "\n",
    "path_to_working_datasets = os.path.abspath('../data/working_data')\n",
    "\n",
    "try: \n",
    "    os.mkdir(path_to_working_datasets)\n",
    "except:\n",
    "    pass\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('../data/working_data/database.db')\n",
    "\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload df to database\n",
    "df.to_sql('all_trials', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test db\n",
    "df_results = pd.read_sql_query(\"SELECT * from all_trials;\", conn)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test string query\n",
    "search_query = pd.read_sql_query(\"SELECT * from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "len(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload count_vectorizer to database\n",
    "# sqlite limit = 2000\n",
    "df_word_counts.to_sql('word_counts', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = pd.read_sql_query(\"SELECT * from word_counts;\", conn)\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List databases\n",
    "pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tweights = transformer.fit_transform(X)\n",
    "tweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn weights data into a dataframe\n",
    "tf = pd.DataFrame(tweights.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms by average tf-idf weight\n",
    "weights = np.asarray(tweights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with nct-id and merge wth tf by index\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_tf = df['nct_id']\n",
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.merge(df_tf, tf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test merged dataframes with tf-idf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def compare_results():\n",
    "#     row = random.randint(0,3000)\n",
    "#     df_tf.drop('nct_id', axis = 1)\n",
    "#     print('Random row: {}'.format(row))\n",
    "#     return df_tf.loc[row], tf.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlation between docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similary\n",
    "similarity = tweights * tweights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all data in a dataframe\n",
    "df_docs_similarity = pd.DataFrame(similarity.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To-do: Give a NTC-ID record, find similar documents\n",
    "& return dataframe with results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find more similar documents of a given record\n",
    "\n",
    "def find_similar_docs(record, rate):\n",
    "    trials_id = []\n",
    "    treshold = rate\n",
    "    similar_index = df_docs_similarity.iloc[record][df_docs_similarity.iloc[record] > treshold].index\n",
    "    \n",
    "    for i in similar_index.values:\n",
    "        trials_id.append(i)\n",
    "        \n",
    "    print('{} similar trials with treshold {}'.format(len(trials_id), treshold))\n",
    "    return df.iloc[trials_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "find_similar_docs(0, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
