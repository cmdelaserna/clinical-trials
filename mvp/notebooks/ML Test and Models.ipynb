{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical trials: ML Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = \"#3298D0\"\n",
    "plot_size = (14, 10)\n",
    "\n",
    "# sys.stdout = open('/dev/stdout', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for csv folder & file\n",
    "path_to_csv_file = os.path.abspath('../data/csv/')\n",
    "\n",
    "# json file\n",
    "csv_file = '/clean_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import json into a dataframe\n",
    "clean_csv_file = '{}{}.csv'.format(path_to_csv_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use dask to improve data loading\n",
    "https://www.kaggle.com/shikhar1/yet-another-pandas-tutorial'''\n",
    "\n",
    "# breaks with large json file\n",
    "df = pd.read_csv(clean_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Unnamed column\n",
    "df = df.drop(columns = ['Unnamed: 0'])\n",
    "df = df.drop(columns = ['original_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'source', 'brief_title', 'condition', 'full_description',\n",
       "       'summary', 'full_date', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index                    80\n",
      "id                    68000\n",
      "source                85638\n",
      "brief_title          144719\n",
      "condition             76732\n",
      "full_description    1613753\n",
      "summary              756582\n",
      "full_date             67000\n",
      "year                   8000\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      "id                  1000 non-null object\n",
      "source              1000 non-null object\n",
      "brief_title         1000 non-null object\n",
      "condition           1000 non-null object\n",
      "full_description    1000 non-null object\n",
      "summary             1000 non-null object\n",
      "full_date           1000 non-null object\n",
      "year                1000 non-null int64\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.memory_usage(deep=True))\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "df['id'] = df['id'].astype('str')\n",
    "for col in ['source', 'condition']:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_date'] =  pd.to_datetime(df['full_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index                    80\n",
      "id                    68000\n",
      "source                80312\n",
      "brief_title          144719\n",
      "condition             77657\n",
      "full_description    1613753\n",
      "summary              756582\n",
      "full_date              8000\n",
      "year                   8000\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      "id                  1000 non-null object\n",
      "source              1000 non-null category\n",
      "brief_title         1000 non-null object\n",
      "condition           1000 non-null category\n",
      "full_description    1000 non-null object\n",
      "summary             1000 non-null object\n",
      "full_date           1000 non-null datetime64[ns]\n",
      "year                1000 non-null int64\n",
      "dtypes: category(2), datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 101.5+ KB\n"
     ]
    }
   ],
   "source": [
    "print(df.memory_usage(deep=True))\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "id                  1000\n",
      "source               662\n",
      "brief_title          999\n",
      "condition            703\n",
      "full_description     665\n",
      "summary              999\n",
      "full_date            862\n",
      "year                  20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of conditions\n",
    "- ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Publications/ICD10CM/2019/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['icd10cm_tabular_2019.xml']\n"
     ]
    }
   ],
   "source": [
    "list_conditions = '../data/icd10/'\n",
    "\n",
    "conditions = []\n",
    "\n",
    "for xml in os.listdir(list_conditions):\n",
    "    conditions.append(xml)\n",
    "\n",
    "print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed: icd10cm_tabular_2019.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "icd = list_conditions + conditions[0] #full path\n",
    "tree = ET.parse(icd).getroot()\n",
    "print('Parsed: {}\\n'.format(conditions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44803"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save titles from xml file in a list\n",
    "all_conditions = []\n",
    "    \n",
    "for i in tree.iter('desc'):\n",
    "    all_conditions.append(i.text)\n",
    "    \n",
    "len(all_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6163"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove long names\n",
    "result = []\n",
    "\n",
    "def count_words_list(words,size):\n",
    "    for w in words:\n",
    "        if len(w.split())<=size:\n",
    "            result.append(w)\n",
    "    return result\n",
    "\n",
    "count_words_list(all_conditions, 3)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean conditions dataset\n",
    "all_conditions = [w.replace('unspecified', '') for w in all_conditions]\n",
    "all_conditions = [w.replace(',', '') for w in all_conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6088"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminate duplicated records\n",
    "all_conditions = list(set(result))\n",
    "len(all_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify docs using a list of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with all text\n",
    "df['text'] = df['brief_title'] + df['summary'] + df['full_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extra blank spaces\n",
    "df.text = df.text.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for values in conditions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store vocabulary\n",
    "vocabulary_conditions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PENDING: faster function\n",
    "# https://stackoverflow.com/questions/44960614/whats-the-fastest-way-to-acces-a-pandas-dataframe\n",
    "for term in all_conditions:\n",
    "    try:\n",
    "        vocabulary_conditions[term] = df['text'].str.contains(term, case = False).astype(int)\n",
    "        print(term)\n",
    "    except:\n",
    "        pass\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_conditions.info()\n",
    "#463 Mb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard columns above a treshold\n",
    "vocabulary_conditions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF transformations\n",
    "- Check which ones can be added to the preprocessor\n",
    "- Info: http://www.ultravioletanalytics.com/blog/tf-idf-basics-with-pandas-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column combining title + full description\n",
    "df['text'] = df['brief_title'] + df['summary'] + df['full_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extra blank spaces\n",
    "df.text = df.text.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_numbers = lambda x: re.sub(r'(\\d)+', '', x.lower())\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                     preprocessor = pat_numbers,\n",
    "                     max_features = 3000,\n",
    "                     lowercase = True,\n",
    "                     max_df = 0.5,\n",
    "                     ngram_range = (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df['full_description'])\n",
    "\n",
    "X = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values in dictionary\n",
    "if 'breast cancer' in list(cv.vocabulary_):\n",
    "  print('yes')\n",
    "else:\n",
    "  print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tweights = transformer.fit_transform(X)\n",
    "tweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending: Reduced dimensionality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn weights data into a dataframe\n",
    "tf = pd.DataFrame(tweights.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms by average tf-idf weight\n",
    "weights = np.asarray(tweights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check word\n",
    "def check_weight(word):\n",
    "    for w in word:\n",
    "        try:\n",
    "            print('{}: {}'.format(w, tf[w].mean()))\n",
    "        except KeyError:\n",
    "            print('{}: None'.format(w))\n",
    "\n",
    "search_terms = ['cancer', 'breast cancer', 'migraine', 'sarcoma']\n",
    "check_weight(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df y tf-idf data by index\n",
    "pd.set_option('display.max_columns', None) \n",
    "tf.sample(5)\n",
    "# pd.merge(df, tf, left_index=True, right_index=True).sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "- https://nlpforhackers.io/topic-modeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Using Tensorflow \n",
    "- https://github.com/open-source-for-science/TensorFlow-Course?utm_campaign=explore-email&utm_medium=email&utm_source=newsletter&utm_term=weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
