{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data into pySpark\n",
    "- https://github.com/titipata/pubmed_parser/wiki/Download-and-preprocess-MEDLINE-dataset\n",
    "\n",
    "- MEDLINE BULK DOWNLOAD -\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pubmed/baseline/*.gz\n",
    "\n",
    "- MEDLINE UPDATES -\n",
    "wget ftp://ftp.ncbi.nlm.nih.gov/pubmed/updatefiles/*.gz\n",
    "- Change JAVA version: https://kodejava.org/how-do-i-set-the-default-java-jdk-version-on-mac-os-x/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pubmed_parser as pp\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import Row\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.\\\n",
    "    config(conf=conf).\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process medline files\n",
    "- https://github.com/titipata/pubmed_parser/wiki/Download-and-preprocess-MEDLINE-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline_files_rdd = spark.sparkContext.parallelize(glob('../data/pubmed/*.gz'), numSlices=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_results_rdd = medline_files_rdd.\\\n",
    "    flatMap(lambda x: [Row(file_name=os.path.basename(x), **publication_dict) \n",
    "                       for publication_dict in pp.parse_medline_xml(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline_df = parse_results_rdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract',\n",
       " 'affiliations',\n",
       " 'authors',\n",
       " 'chemical_list',\n",
       " 'country',\n",
       " 'delete',\n",
       " 'doi',\n",
       " 'file_name',\n",
       " 'issn_linking',\n",
       " 'journal',\n",
       " 'keywords',\n",
       " 'medline_ta',\n",
       " 'mesh_terms',\n",
       " 'nlm_unique_id',\n",
       " 'other_id',\n",
       " 'pmc',\n",
       " 'pmid',\n",
       " 'pubdate',\n",
       " 'publication_types',\n",
       " 'references',\n",
       " 'title']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medline_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create view, run sql queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create view as temporary table\n",
    "medline_df.createOrReplaceTempView(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[count(1): bigint]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find distint countries, show 10 first results\n",
    "spark.sql(\"select count(*) from table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to parquet\n",
    "# medline_df.write.parquet('raw_medline.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process updates\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import rank, max, sum, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(['pmid']).orderBy(desc('file_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed_df = medline_df.select(\n",
    "    max('delete').over(window).alias('is_deleted'),\n",
    "    rank().over(window).alias('pos'),\n",
    "    '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF in all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(df, \"table1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify with Fastest\n",
    "- https://www.futurice.com/blog/classifying-text-with-fasttext-in-pyspark\n",
    "- https://fasttext.cc/docs/en/supervised-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
