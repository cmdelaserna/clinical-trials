{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical trials: ML Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = \"#3298D0\"\n",
    "plot_size = (14, 10)\n",
    "\n",
    "# sys.stdout = open('/dev/stdout', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for csv folder & file\n",
    "path_to_csv_file = os.path.abspath('../data/csv/')\n",
    "\n",
    "# json file\n",
    "csv_file = '/clean_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import json into a dataframe\n",
    "clean_csv_file = '{}{}.csv'.format(path_to_csv_file, csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use dask to improve data loading\n",
    "https://www.kaggle.com/shikhar1/yet-another-pandas-tutorial'''\n",
    "\n",
    "# breaks with large json file\n",
    "df = pd.read_csv(clean_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Unnamed column\n",
    "df = df.drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.memory_usage(deep=True))\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change data types\n",
    "df['id'] = df['id'].astype('str')\n",
    "for col in ['source', 'condition', 'city', 'country']:\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_date'] =  pd.to_datetime(df['full_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['zip', 'mesh_term_condition', 'mesh_term_intervention']:\n",
    "    df[col] = df[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.memory_usage(deep=True))\n",
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete records before 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep records since 2008\n",
    "df = df[df['year'] > 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.nunique())\n",
    "print('\\n{}'.format(df.year.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save conditions, mesh terms and sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list_of_terms(column, final_list):\n",
    "    for term in df[column]:\n",
    "        final_list.append(term)\n",
    "        # Keep only unique values\n",
    "    final_list = sorted(set(final_list))\n",
    "    print('Number of {}: {}'.format(column, len(final_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conditions = []\n",
    "save_list_of_terms('condition', all_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mesh_conditions = []\n",
    "save_list_of_terms('mesh_term_condition', all_mesh_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mesh_interventions = []\n",
    "save_list_of_terms('mesh_term_intervention', all_mesh_interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sources = []\n",
    "save_list_of_terms('source', all_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference: List of conditions\n",
    "- ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/Publications/ICD10CM/2019/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_conditions = '../data/icd10/'\n",
    "\n",
    "conditions = []\n",
    "\n",
    "for xml in os.listdir(list_conditions):\n",
    "    conditions.append(xml)\n",
    "\n",
    "print(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd = list_conditions + conditions[0] #full path\n",
    "tree = ET.parse(icd).getroot()\n",
    "print('Parsed: {}\\n'.format(conditions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save titles from xml file in a list\n",
    "all_conditions = []\n",
    "    \n",
    "for i in tree.iter('desc'):\n",
    "    all_conditions.append(i.text)\n",
    "    \n",
    "len(all_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove long names\n",
    "result = []\n",
    "\n",
    "def count_words_list(words,size):\n",
    "    for w in words:\n",
    "        if len(w.split())<=size:\n",
    "            result.append(w)\n",
    "    return result\n",
    "\n",
    "count_words_list(all_conditions, 3)\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean conditions dataset\n",
    "all_conditions = [w.replace('unspecified', '') for w in all_conditions]\n",
    "all_conditions = [w.replace(',', '') for w in all_conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate duplicated records\n",
    "all_conditions = list(set(result))\n",
    "len(all_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify docs using a list of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column with all text\n",
    "df['text'] = df['brief_title'] + df['summary'] + df['full_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extra blank spaces\n",
    "df.text = df.text.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for values in conditions list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store vocabulary\n",
    "vocabulary_conditions = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PENDING: faster function\n",
    "# https://stackoverflow.com/questions/44960614/whats-the-fastest-way-to-acces-a-pandas-dataframe\n",
    "for term in all_conditions:\n",
    "    try:\n",
    "        vocabulary_conditions[term] = df['text'].str.contains(term, case = False).astype(int)\n",
    "        print(term)\n",
    "    except:\n",
    "        pass\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_conditions.info()\n",
    "#463 Mb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard columns above a treshold\n",
    "vocabulary_conditions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF transformations\n",
    "- Check which ones can be added to the preprocessor\n",
    "- Info: http://www.ultravioletanalytics.com/blog/tf-idf-basics-with-pandas-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column combining title + full description\n",
    "df['text'] = df['brief_title'] + df['summary'] + df['full_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extra blank spaces\n",
    "df.text = df.text.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_numbers = lambda x: re.sub(r'(\\d)+', '', x.lower())\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                     preprocessor = pat_numbers,\n",
    "                     max_features = 3000,\n",
    "                     lowercase = True,\n",
    "                     max_df = 0.5,\n",
    "                     ngram_range = (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df['full_description'])\n",
    "\n",
    "X = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values in dictionary\n",
    "if 'breast cancer' in list(cv.vocabulary_):\n",
    "  print('yes')\n",
    "else:\n",
    "  print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.toarray(), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tweights = transformer.fit_transform(X)\n",
    "tweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending: Reduced dimensionality\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn weights data into a dataframe\n",
    "tf = pd.DataFrame(tweights.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms by average tf-idf weight\n",
    "weights = np.asarray(tweights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check word\n",
    "def check_weight(word):\n",
    "    for w in word:\n",
    "        try:\n",
    "            print('{}: {}'.format(w, tf[w].mean()))\n",
    "        except KeyError:\n",
    "            print('{}: None'.format(w))\n",
    "\n",
    "search_terms = ['cancer', 'breast cancer', 'migraine', 'sarcoma']\n",
    "check_weight(search_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df y tf-idf data by index\n",
    "pd.set_option('display.max_columns', None) \n",
    "tf.sample(5)\n",
    "# pd.merge(df, tf, left_index=True, right_index=True).sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling\n",
    "- https://nlpforhackers.io/topic-modeling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Using Tensorflow \n",
    "- https://github.com/open-source-for-science/TensorFlow-Course?utm_campaign=explore-email&utm_medium=email&utm_source=newsletter&utm_term=weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
