{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare working db\n",
    "- Load data\n",
    "- df cleaning\n",
    "- Create label for recruting status\n",
    "- Export full dataset to sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load json file with parsed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "path_to_json_file = os.path.abspath('../data/json/')\n",
    "\n",
    "### json file\n",
    "# json_file = '/all_parsed_data_json' #name json file  \n",
    "json_file = '/sample_json' #sample json file for testing  \n",
    "\n",
    "file = '{}{}.json'.format(path_to_json_file, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "df = pd.read_json(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full dataframe\n",
    "# pd.set_option('display.max_rows', 50)\n",
    "# pd.set_option('display.max_columns', 50)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5984, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all_files folder\n",
    "path_to_all_files = os.path.abspath('../data/all_trials//')\n",
    "\n",
    "def remove_extra_folders(folder):\n",
    "    try:\n",
    "        shutil.rmtree(folder)\n",
    "        print(\"\\nunzip folder deleted\")\n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/cmserna/Sites/clinical trials/mvp/data/all_trials'\n",
      "CPU times: user 514 µs, sys: 654 µs, total: 1.17 ms\n",
      "Wall time: 836 µs\n"
     ]
    }
   ],
   "source": [
    "%time remove_extra_folders(path_to_all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>study_first_submitted</th>\n",
       "      <th>source</th>\n",
       "      <th>brief_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>verification_date</th>\n",
       "      <th>study_type</th>\n",
       "      <th>study_first_posted</th>\n",
       "      <th>last_update_submitted</th>\n",
       "      <th>last_update_posted</th>\n",
       "      <th>...</th>\n",
       "      <th>detailed_description/textblock</th>\n",
       "      <th>brief_summary/textblock</th>\n",
       "      <th>location/facility/address/city</th>\n",
       "      <th>location/facility/address/country</th>\n",
       "      <th>location/facility/address/zip</th>\n",
       "      <th>sponsors/lead_sponsor/agency</th>\n",
       "      <th>sponsors/lead_sponsor/agency_class</th>\n",
       "      <th>study_design_info/allocation</th>\n",
       "      <th>study_design_info/intervention_model</th>\n",
       "      <th>study_design_info/primary_purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT01236404</td>\n",
       "      <td>November 5, 2010</td>\n",
       "      <td>PhaseBio Pharmaceuticals Inc.</td>\n",
       "      <td>Phase 1/2a, Randomized, Double-Blind, Placebo-...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>May 2013</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>November 8, 2010</td>\n",
       "      <td>May 13, 2013</td>\n",
       "      <td>May 21, 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n      Primary objective:\\n\\n      To evaluat...</td>\n",
       "      <td>Walnut Creek</td>\n",
       "      <td>United States</td>\n",
       "      <td>94598</td>\n",
       "      <td>PhaseBio Pharmaceuticals Inc.</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00275600</td>\n",
       "      <td>January 10, 2006</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>Randomized Clinical Trial of Vitamin E and Eve...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>November 2009</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>January 12, 2006</td>\n",
       "      <td>November 25, 2009</td>\n",
       "      <td>November 26, 2009</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n      Cyclical mastalgia is a common complai...</td>\n",
       "      <td>\\n      This study is being done to find out w...</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>United States</td>\n",
       "      <td>55905</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCT01810211</td>\n",
       "      <td>March 8, 2013</td>\n",
       "      <td>Nova Southeastern University</td>\n",
       "      <td>The Most Effective Intervention for Reducing P...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>March 2014</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>March 13, 2013</td>\n",
       "      <td>September 24, 2014</td>\n",
       "      <td>September 26, 2014</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n      This study will look at which, if any,...</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>United States</td>\n",
       "      <td>27609</td>\n",
       "      <td>Nova Southeastern University</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NCT00826111</td>\n",
       "      <td>January 19, 2009</td>\n",
       "      <td>Steward St. Elizabeth's Medical Center of Bost...</td>\n",
       "      <td>The Effects of Eszopiclone and Lexapro on Pref...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>June 2012</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>January 21, 2009</td>\n",
       "      <td>June 28, 2012</td>\n",
       "      <td>June 29, 2012</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n      The study examined the effects of addi...</td>\n",
       "      <td>Boston</td>\n",
       "      <td>United States</td>\n",
       "      <td>02135</td>\n",
       "      <td>Steward St. Elizabeth's Medical Center of Bost...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NCT02813850</td>\n",
       "      <td>June 23, 2016</td>\n",
       "      <td>Assistance Publique - Hôpitaux de Paris</td>\n",
       "      <td>Oxygen Therapy and Pregnancy in Sickle Cell Di...</td>\n",
       "      <td>Recruiting</td>\n",
       "      <td>March 2017</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>June 27, 2016</td>\n",
       "      <td>December 20, 2017</td>\n",
       "      <td>December 21, 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>\\n      Sickle cell disease (SCD) corresponds ...</td>\n",
       "      <td>\\n      The purpose of this study is to assess...</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "      <td>75015</td>\n",
       "      <td>Assistance Publique - Hôpitaux de Paris</td>\n",
       "      <td>Other</td>\n",
       "      <td>Randomized</td>\n",
       "      <td>Parallel Assignment</td>\n",
       "      <td>Prevention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           nct_id study_first_submitted  \\\n",
       "0     NCT01236404      November 5, 2010   \n",
       "1     NCT00275600      January 10, 2006   \n",
       "10    NCT01810211         March 8, 2013   \n",
       "100   NCT00826111      January 19, 2009   \n",
       "1000  NCT02813850         June 23, 2016   \n",
       "\n",
       "                                                 source  \\\n",
       "0                         PhaseBio Pharmaceuticals Inc.   \n",
       "1                                           Mayo Clinic   \n",
       "10                         Nova Southeastern University   \n",
       "100   Steward St. Elizabeth's Medical Center of Bost...   \n",
       "1000            Assistance Publique - Hôpitaux de Paris   \n",
       "\n",
       "                                            brief_title overall_status  \\\n",
       "0     Phase 1/2a, Randomized, Double-Blind, Placebo-...      Completed   \n",
       "1     Randomized Clinical Trial of Vitamin E and Eve...      Completed   \n",
       "10    The Most Effective Intervention for Reducing P...      Completed   \n",
       "100   The Effects of Eszopiclone and Lexapro on Pref...      Completed   \n",
       "1000  Oxygen Therapy and Pregnancy in Sickle Cell Di...     Recruiting   \n",
       "\n",
       "     verification_date      study_type study_first_posted  \\\n",
       "0             May 2013  Interventional   November 8, 2010   \n",
       "1        November 2009  Interventional   January 12, 2006   \n",
       "10          March 2014  Interventional     March 13, 2013   \n",
       "100          June 2012  Interventional   January 21, 2009   \n",
       "1000        March 2017  Interventional      June 27, 2016   \n",
       "\n",
       "     last_update_submitted  last_update_posted  ...  \\\n",
       "0             May 13, 2013        May 21, 2013  ...   \n",
       "1        November 25, 2009   November 26, 2009  ...   \n",
       "10      September 24, 2014  September 26, 2014  ...   \n",
       "100          June 28, 2012       June 29, 2012  ...   \n",
       "1000     December 20, 2017   December 21, 2017  ...   \n",
       "\n",
       "                         detailed_description/textblock  \\\n",
       "0                                                  None   \n",
       "1     \\n      Cyclical mastalgia is a common complai...   \n",
       "10                                                 None   \n",
       "100                                                None   \n",
       "1000  \\n      Sickle cell disease (SCD) corresponds ...   \n",
       "\n",
       "                                brief_summary/textblock  \\\n",
       "0     \\n      Primary objective:\\n\\n      To evaluat...   \n",
       "1     \\n      This study is being done to find out w...   \n",
       "10    \\n      This study will look at which, if any,...   \n",
       "100   \\n      The study examined the effects of addi...   \n",
       "1000  \\n      The purpose of this study is to assess...   \n",
       "\n",
       "     location/facility/address/city location/facility/address/country  \\\n",
       "0                      Walnut Creek                     United States   \n",
       "1                         Rochester                     United States   \n",
       "10                          Raleigh                     United States   \n",
       "100                          Boston                     United States   \n",
       "1000                          Paris                            France   \n",
       "\n",
       "     location/facility/address/zip  \\\n",
       "0                            94598   \n",
       "1                            55905   \n",
       "10                           27609   \n",
       "100                          02135   \n",
       "1000                         75015   \n",
       "\n",
       "                           sponsors/lead_sponsor/agency  \\\n",
       "0                         PhaseBio Pharmaceuticals Inc.   \n",
       "1                                           Mayo Clinic   \n",
       "10                         Nova Southeastern University   \n",
       "100   Steward St. Elizabeth's Medical Center of Bost...   \n",
       "1000            Assistance Publique - Hôpitaux de Paris   \n",
       "\n",
       "     sponsors/lead_sponsor/agency_class study_design_info/allocation  \\\n",
       "0                              Industry                   Randomized   \n",
       "1                                 Other                   Randomized   \n",
       "10                                Other                   Randomized   \n",
       "100                               Other                   Randomized   \n",
       "1000                              Other                   Randomized   \n",
       "\n",
       "     study_design_info/intervention_model study_design_info/primary_purpose  \n",
       "0                     Parallel Assignment                         Treatment  \n",
       "1                     Parallel Assignment                         Treatment  \n",
       "10                    Parallel Assignment                         Treatment  \n",
       "100                   Parallel Assignment                         Treatment  \n",
       "1000                  Parallel Assignment                        Prevention  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to change column type\n",
    "\n",
    "def data_types(dataframe, cols = [], to_type = ''):\n",
    "    for col in cols:\n",
    "        dataframe[col] = df[col].astype(to_type)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904         July 2018\n",
       "4523       April 2016\n",
       "1455     October 2012\n",
       "3481       March 2016\n",
       "3106       March 2018\n",
       "2783    December 2017\n",
       "5164      August 2012\n",
       "5579     October 2018\n",
       "3566       March 2018\n",
       "1361    December 2012\n",
       "Name: verification_date, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['verification_date'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change date types, extract years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dates = ['study_first_submitted', 'last_update_submitted', 'verification_date']\n",
    "data_types(df, columns_dates, 'datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year \n",
    "df['year_submitted'] = df['study_first_submitted'].dt.year\n",
    "df['year_last_updated'] = df['last_update_submitted'].dt.year\n",
    "df['verification_year'] = df['verification_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecesary columns\n",
    "# df.drop(columns_dates, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['study_first_posted', 'last_update_posted', 'verification_date']\n",
    "# df.drop(columns_to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove /n in all df\n",
    "df = df.replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for all text\n",
    "df['all_text'] = df['source'] + ' ' + df['brief_title'] + ' ' + df['condition'] + ' ' + df['condition_browse/mesh_term'] + ' '+ df['intervention_browse/mesh_term'] + ' '+ df['detailed_description/textblock'] + ' ' + df['brief_summary/textblock']\n",
    "\n",
    "# All_text in lowercase\n",
    "df['all_text'] = df['all_text'].str.lower()\n",
    "\n",
    "# remove extra whitespace\n",
    "df.all_text = df.all_text.replace('\\s+', ' ', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra white space in summary\n",
    "df['brief_summary/textblock'] = df['brief_summary/textblock'].replace('\\s+', ' ', regex=True)\n",
    "df['brief_summary/textblock'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add url columns\n",
    "url_string = 'https://clinicaltrials.gov/ct2/show/'\n",
    "df['url'] = url_string + df['nct_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recruiting status\n",
    "- Create criteria for filtering recruiting status\n",
    "- Create new column with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Recruiting status \n",
    "0 - Not recruting, including all records not updated \n",
    "1 - Possibily recruiting. Define time range for category \n",
    "2 - Recruiting\n",
    "\n",
    "'''\n",
    "\n",
    "df.overall_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting open trials\n",
    "# https://clinicaltrials.gov/ct2/help/glossary/recruitment-status\n",
    "\n",
    "recruiting = df[(df['overall_status'] == \"Recruiting\") | \\\n",
    "                (df['overall_status'] == \"Not yet recruiting\") | \\\n",
    "                (df['overall_status'] == \"Available for expanded access\")]\n",
    "\n",
    "# Check recruiting studies\n",
    "print('Total of trials classified as recruiting: {}'.format(len(recruiting)))\n",
    "\n",
    "print('Trials not verified in the last two years 2017-2019: {}'.\\\n",
    "      format(len(recruiting[recruiting['verification_year'] < 2017])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiting.overall_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials by verification date\n",
    "\n",
    "'''Unknown: A study with a status of Recruiting, Not yet recruiting, \n",
    "or Active, not recruiting and whose status has not been verified within the past 2 years. \n",
    "\n",
    "** Studies with an Unknown recruitment status are considered open studies or closed studies, \n",
    "depending on their last known recruitment status**\n",
    "\n",
    "'''\n",
    "recruiting.boxplot(column='verification_year', by='overall_status', \\\n",
    "                   figsize=(14,9), showfliers=False, meanline=True,\\\n",
    "                   whiskerprops = dict(linestyle='-.', linewidth=2))\n",
    "\n",
    "# recruiting.boxplot(column='year_last_updated')\n",
    "# recruiting['verification_year'].plot(kind='box', figsize=(10,7))\n",
    "# recruiting['year_last_updated'].plot(kind='box', figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with recruiting status based on verification date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign recruiting labels\n",
    "options = [\n",
    "    (df['verification_year'] < 2017),\n",
    "    (df['verification_year'] > 2017) &\n",
    "    (df['year_last_updated'] > 2017) & \n",
    "    (df['overall_status'] == \"Recruiting\") | \\\n",
    "                (df['overall_status'] == \"Not yet recruiting\") | \\\n",
    "                (df['overall_status'] == \"Available for expanded access\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1]\n",
    "df['recruiting_labels'] = np.select(options, labels, default=0)\n",
    "df['recruiting_labels'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recruiting = df[df['recruiting_labels'] == 1].sort_values('study_first_submitted')\n",
    "print('Verification years: {}'.format(all_recruiting['verification_year'].unique()))\n",
    "print('Verification dates: {}'.format(all_recruiting['verification_date'].unique()))\n",
    "print('Year last udpated: {}'.format(all_recruiting['year_last_updated'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recruiting['verification_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_recruiting.boxplot(column='recruiting_labels', by='sverification_date', \\\n",
    "#                    figsize=(14,9), showfliers=False, meanline=True,\\\n",
    "#                    whiskerprops = dict(linestyle='-.', linewidth=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder\n",
    "\n",
    "path_to_working_datasets = os.path.abspath('../data/working_data')\n",
    "\n",
    "try: \n",
    "    os.mkdir(path_to_working_datasets)\n",
    "except:\n",
    "    pass\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and connect to db\n",
    "conn = sqlite3.connect('../data/working_data/working-database.db')\n",
    "conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload df to database: define schema\n",
    "%time df.to_sql('all_trials', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of indexes\n",
    "pd.read_sql_query(\"PRAGMA index_list(all_trials);\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1. Filter by condition\n",
    "%time search_query = pd.read_sql_query(\"SELECT * from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "search_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2. Filter by recruiting status = 1\n",
    "%time search_query = pd.read_sql_query(\"SELECT * from all_trials WHERE recruiting_labels == 1;\", conn)\n",
    "len(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index on all_text column\n",
    "c = conn.cursor()\n",
    "%time c.execute(\"CREATE INDEX idx1 ON all_trials(all_text)\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of indexes\n",
    "pd.read_sql_query(\"PRAGMA index_list(all_trials);\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test new query\n",
    "%time search_query = pd.read_sql_query(\"SELECT * from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "search_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time new_query = pd.read_sql_query(\"SELECT nct_id from all_trials WHERE all_text LIKE '%breast cancer%';\", conn).head()\n",
    "new_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Optimize performance\n",
    "https://medium.com/@JasonWyatt/squeezing-performance-from-sqlite-indexes-indexes-c4e175f3c346\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test queries speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "# pd.read_sql_query(\"PRAGMA table_info(all_trials);\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time query with WHERE condition\n",
    "%time search_query = pd.read_sql_query(\"SELECT * from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "search_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time query with WHERE condition, return nct_id\n",
    "%time filtered_query = pd.read_sql_query(\"SELECT nct_id from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "filtered_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original index\n",
    "%time c.execute(\"DROP INDEX ix_all_trials_index\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test queries after creating index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time query with WHERE condition after creating index\n",
    "%time optimized_query = pd.read_sql_query(\"SELECT * from all_trials WHERE all_text LIKE '%breast cancer%';\", conn)\n",
    "optimized_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return only nct_id\n",
    "%time new_query = pd.read_sql_query(\"SELECT nct_id from all_trials WHERE all_text LIKE '%breast cancer%';\", conn).head()\n",
    "new_query.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pending: Test search pattern to optimize queries, return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "- Tokenize, Lemmatize / Stem\n",
    "- Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "# porter_stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# def stem_sentences(text):\n",
    "#     tokens = text.split()\n",
    "#     stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "#     return ' '.join(stemmed_tokens)\n",
    "\n",
    "# df['stems'] = df['all_text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing\n",
    "def lemm_sentences(text):\n",
    "    tokens = text.split()\n",
    "    lemm_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemm_tokens)\n",
    "\n",
    "df['lemmas'] = df['all_text'].apply(lemm_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words [not needed with countvectorizer]\n",
    "# stop_words = stopwords.words('english')\n",
    "# df['tokens'] = df['lemmas'].apply(lambda x: [item for item in x.split() if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lemmas[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_numbers = lambda x: re.sub(r'(\\d)+', '', x.lower())\n",
    "\n",
    "cv = CountVectorizer(stop_words='english',\n",
    "                     preprocessor = pat_numbers,\n",
    "                     max_features = 1800,\n",
    "                     lowercase = True,\n",
    "                     max_df = 0.8,\n",
    "                     ngram_range = (1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df['lemmas'])\n",
    "\n",
    "X = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(X.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add nct_id to word_counts df\n",
    "nct_id = df['nct_id']\n",
    "\n",
    "df_word_counts = pd.merge(nct_id, word_counts, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all dataframes in space\n",
    "%who DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload count_vectorizer to database\n",
    "# sqlite limit = 2000\n",
    "df_word_counts.to_sql('word_counts', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = pd.read_sql_query(\"SELECT * from word_counts;\", conn)\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List databases\n",
    "pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()\n",
    "tweights = transformer.fit_transform(X)\n",
    "tweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn weights data into a dataframe\n",
    "tf = pd.DataFrame(tweights.toarray(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top terms by average tf-idf weight\n",
    "weights = np.asarray(tweights.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': cv.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with nct-id and merge wth tf by index\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_tf = df['nct_id']\n",
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf = pd.merge(df_tf, tf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test merged dataframes with tf-idf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def compare_results():\n",
    "#     row = random.randint(0,3000)\n",
    "#     df_tf.drop('nct_id', axis = 1)\n",
    "#     print('Random row: {}'.format(row))\n",
    "#     return df_tf.loc[row], tf.loc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlation between docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate similary\n",
    "similarity = tweights * tweights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all data in a dataframe\n",
    "df_docs_similarity = pd.DataFrame(similarity.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>To-do: Give a NTC-ID record, find similar documents\n",
    "& return dataframe with results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find more similar documents of a given record\n",
    "\n",
    "def find_similar_docs(record, rate):\n",
    "    trials_id = []\n",
    "    treshold = rate\n",
    "    similar_index = df_docs_similarity.iloc[record][df_docs_similarity.iloc[record] > treshold].index\n",
    "    \n",
    "    for i in similar_index.values:\n",
    "        trials_id.append(i)\n",
    "        \n",
    "    print('{} similar trials with treshold {}'.format(len(trials_id), treshold))\n",
    "    return df.iloc[trials_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "find_similar_docs(0, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
